\documentclass[12pt, A4]{article}

\usepackage[OT4]{polski}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage{booktabs}
\usepackage{indentfirst}
\usepackage{float}
\usepackage{amssymb, amsfonts, amsmath}

\title{Sprawozdanie 2}
\author{Antczak Jakub, Curkowicz Kinga}
\date{\today}

\begin{document}

\maketitle
\tableofcontents


<<include=FALSE>>=
pdf.options(encoding='CP1250')
library(BSDA)
library(dplyr)
library(tidyr)
library(ggplot2)
library(latex2exp)
library(stats)
library(exactRankTests)
knitr::opts_chunk$set(fig.width=7, fig.height=5,
                      fig.align='center', fig.path='Figs/',
                      echo=T, warning=F, message=F)
color1 <- "#ED79A9"
color2 <- "#32BDD9"
color3 <- "#bb9cf1"
color4 <- "#20b2aa"
color5 <- "#f08080"

colors <- c("t-Studenta"=color1,"t-Welcha"=color2, "Wilcoxona"=color3, "Wilocoxona z korektą"=color5)
@

\section{Wprowadzenie}

Niniejsze sprawozdanie stanowi analizę porównawczą wybranych testów statystycznych. Będą to:
\begin{itemize}
\item test \emph{t}-studenta przy założeniu, że $\sigma_{1}=\sigma_{2}$,
\item test \emph{t}-Welcha,
\item test sumy rang Wilcoxona.
\end{itemize}

\section{Opisy testów}
\label{sec:tests}

\subsection{Test \emph{t}-studenta}

Zakładamy, że $X_1,\,\ldots,X_n$ pochodzą z rozkładu $\mathcal{N}(\mu, \sigma^2)$. Tym razem nie zakładamy znajomości $\sigma^2$ --- jest ona nieznana. Test \emph{t}-studenta opiera się na statystyce
\begin{align*}
  T = \sqrt{n}\frac{\bar{X} - \mu_0}{S},
\end{align*}

gdzie $S = \sqrt{\frac{1}{n-1}\sum_{i=1}^n\left(X_i-\bar{X}\right)^2}$. Przy prawdziwej hipotezie zerowej $T\sim\mathcal{T}(n-1)$ --- pochodzi z rozkładu \emph{t}-studenta z $n-1$ stopniami swobody. Dla rozpatrywanej przez nas hipotezy alternatywnej p-wartość zadana jest wzorem
\begin{align*}
  p = 1 - F_{n-1}\left(\sqrt{n}\frac{\bar{X}-\mu_0}{S}\right),
\end{align*}

gdzie $F_{n-1}$ to dystrybuanta rozkładu \emph{t}-Studenta z $n-1$ stopniami swobody.

\subsection{Test \emph{t}-Welcha}

Test t-Welcha zakłada, że wariancje dwóch prób, oznaczone jako $S^2_X$ i $S^2_Y$ dla prób \(X\) i \(Y\) odpowiednio, są nieznane i różne. Aby przybliżyć rozkład wariancji połączonej (\(S^2_{WS}\)), można skorzystać z równania Welch-Satterthwaite'a. Równanie to jest opisane następująco:

\begin{equation*}
S^2_{WS} = \frac{S^2_X}{n_X} + \frac{S^2_Y}{n_Y}
\end{equation*}

W przybliżeniu, statystyka testu t-Welcha, oznaczana jako \(t\), ma rozkład t-Studenta z \(\nu\) stopniami swobody, gdzie

\begin{equation*}
\nu \approx \frac{\left(\frac{S^2_X}{n_X} + \frac{S^2_Y}{n_Y}\right)^2}{\frac{\frac{S^4_X}{n^2_X}}{(n_X-1)} + \frac{\frac{S^4_Y}{n^2_Y}}{(n_Y-1)}}
\end{equation*}

Przy założeniu hipotezy zerowej, statystyka testu t-Welcha jest wyrażona jako:

\begin{equation*}
t = \frac{\bar{X} - \bar{Y}}{S_{WS}}
\end{equation*}

gdzie \(\bar{X}\) to średnia dla próby \(X\), \(\bar{Y}\) to średnia dla próby \(Y\), \(n_X\) to liczba obserwacji w próbie \(X\), a \(n_Y\) to liczba obserwacji w próbie \(Y\). Test t-Welcha jest standardowym podejściem do porównywania średnich dwóch prób w sytuacji, gdy wariancje są różne.


\subsection{Test sumy rang Wilcoxona}

Dla dwóch zmiennych niezależnych używany jest test sumy rang Wilcoxona, nazywany również testem U Manna-Whitneya. Zakładamy, że zmienne losowe $X_1, \ldots, X_n$ są niezależne i pochodzą z rozkładu o dystrybuancie $F$, natomiast $Y_1, \ldots, Y_m$ są niezależne i pochodzą z rozkładu o dystrybuancie $G$. Dodatkowo zmienne $X_i$ i $Y_j$ są niezależne dla każdego $i$ oraz $j$. Hipoteza w teście to $H_0: X =_{\text{st}} Y$, przeciwko jednej z trzech hipotez alternatywnych: $H_1: X <_{\text{st}} Y$, $H_1: X >_{\text{st}} Y$, $H_1: \bar{X} <_{\text{st}} \bar{Y} \quad \text{lub} \quad \bar{X} >_{\text{st}} \bar{Y}$.

Test opiera się na porównaniu sumy rang dla obu prób. Jeśli dystrybuanty $F$ i $G$ są różne, to można oczekiwać, że suma rang jednej próby będzie zazwyczaj większa niż suma rang drugiej próby.

Jeśli zmienne losowe są ciągłymi zmiennymi losowymi z rozkładu z parametrem przesunięcia i skali, czyli dystrybuanty są postaci $F_{\mu, \sigma}(t) = F_0\left(\frac{t - \mu}{\sigma}\right)$, hipotezy można przetłumaczyć na hipotezy o pseudomedianach. Pseudomediana to mediana zmiennej losowej $\frac{X_1 + X_2}{2}$, gdzie $X_1$ i $X_2$ są niezależnymi kopiami tej samej zmiennej losowej.

Test Wilcoxona dla dwóch prób dotyczy median na podstawie porównania sumy rang obu prób, co pozwala stwierdzić, czy zmienne losowe pochodzą z tych samych rozkładów.

\subsection{Przykładowe wywołanie w R dla zadania 1}
<<wywolanie prawdziwe, include=TRUE>>=
mu_diff_range <- seq(-2, 2, by = 0.05)
n <- 200
sigma <- 2
alpha <- 0.05
num_simulations <- 10000

# Funkcja obliczająca moc dla testu t-Studenta
power_t_student <- function(mu_diff, sigma, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma)
    
    test_result <- t.test(group1, group2, var.equal = TRUE)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

# Funkcja obliczająca moc dla testu t-Welcha
power_t_welch <- function(mu_diff, sigma, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma)
    
    test_result <- t.test(group1, group2)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

# Funkcja obliczająca moc dla testu Wilcoxona
power_wilcox <- function(mu_diff, sigma, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma)
    
    test_result <- wilcox.test(group1, group2, alternative = "greater")
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}


# Obliczenia funkcji mocy dla każdego testu
#power_t1 <- sapply(mu_diff_range, power_t_student, sigma, n, num_simulations, alpha)

#power_welch1 <- sapply(mu_diff_range, power_t_welch, sigma, n, num_simulations, alpha)

#power_wilcox1 <- sapply(mu_diff_range, power_wilcox, sigma, n, num_simulations, alpha)

# Tworzenie ramki danych
#df1 <- data.frame(mu_diff = mu_diff_range, power_t_student = power_t1, power_t_welch = power_welch1, power_wilcox = power_wilcox1)
#write.csv(df1, file = "zad1.csv")
@


\section{Zadania}

Przejdziemy teraz do rozwiązania zadań, w których rozważymy testy opisane w sekcji \ref{sec:tests}. Wszystkie testy zostaną wykonane dla poziomu istotności $\alpha = 0.05$. Będziemy sprawdzać hipotezy $H_0: \mu_1 = \mu_2, \quad \text{przeciwko} \quad H_1: \mu_1 > \mu_2$. W przypadku każdego testu moc testu będziemy wyzanczać symulacyjnie przy użyciu metody Monte Carlo, a wyniki zaprezentujemy na wykresach.

Moc testu statystycznego, znana także jako siła testu, jest prawdopodobieństwem prawidłowego odrzucenia hipotezy zerowej, gdy jest ona fałszywa. Innymi słowy, jest to zdolność testu do wykrywania efektu, jeśli taki efekt rzeczywiście istnieje. Wartość mocy leży w zakresie od 0 do 1, gdzie wartości bliższe 1 wskazują na większą zdolność testu do wykrywania istotnych różnic lub efektów.

Będziemy wykorzystywać metodę Monte Carlo, która w kontekście testowania hipotez statystycznych,do estymacji mocy testu statystycznego poprzez generowanie wielu próbek z określonych rozkładów i obliczanie odsetka przypadków, w których test prawidłowo odrzuca hipotezę zerową, kiedy jest ona fałszywa.

\subsection{Zadanie 1}

Rozważmy dwie niezależne próby losowe $X$ i $Y$, które pochodzą z rozkładu normalnego o średnich $\mu_1$ i $\mu_2$ oraz tej samej wariancji $\sigma^2$.
Korzystając z symulacji Monte Carlo, wykonamy wykres funkcji mocy w zależności od $\mu_2 - \mu_1$ na przedziale $(-2, 2)$ dla wszystkich trzech testów. Sprawdzimy, czy istnieje test jednostajnie najmocniejszy spośród rozważanych.

<<zad1, include= FALSE>>=
mu_diff_range <- seq(-2, 2, by = 0.05)
n <- 200
sigma <- 2
alpha <- 0.05
num_simulations <- 10000

# Funkcja obliczająca moc dla testu t-Studenta
power_t_student <- function(mu_diff, sigma, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma)
    
    test_result <- t.test(group1, group2, var.equal = TRUE)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

# Funkcja obliczająca moc dla testu t-Welcha
power_t_welch <- function(mu_diff, sigma, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma)
    
    test_result <- t.test(group1, group2)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

# Funkcja obliczająca moc dla testu Wilcoxona
power_wilcox <- function(mu_diff, sigma, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma)
    
    test_result <- wilcox.test(group1, group2, alternative = "greater")
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}


# Obliczenia funkcji mocy dla każdego testu
#power_t1 <- sapply(mu_diff_range, power_t_student, sigma, n, num_simulations, alpha)
#power_welch1 <- sapply(mu_diff_range, power_t_welch, sigma, n, num_simulations, alpha)
#power_wilcox1 <- sapply(mu_diff_range, power_wilcox, sigma, n, num_simulations, alpha)

# Tworzenie ramki danych
#df1 <- data.frame(mu_diff = mu_diff_range, power_t_student = power_t1, power_t_welch = power_welch1, power_wilcox = power_wilcox1)
#write.csv(df1, file = "zad1.csv")
@

<<zad 1 rozne n, include=FALSE>>=
mu_diff_range <- seq(-2, 2, by = 0.05)
sigma <- 2
alpha <- 0.05
num_simulations <- 10000

power_t_student <- function(mu_diff, sigma, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma)
    
    test_result <- t.test(group1, group2, var.equal = TRUE)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

# Funkcja obliczająca moc dla testu t-Welcha
power_t_welch <- function(mu_diff, sigma, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma)
    
    test_result <- t.test(group1, group2)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

# Funkcja obliczająca moc dla testu Wilcoxona
power_wilcox <- function(mu_diff, sigma, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma)
    
    test_result <- wilcox.test(group1, group2, alternative = "greater")
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}
#power_t1_10 <- sapply(mu_diff_range, power_t_student, sigma, 10, num_simulations, alpha)
#power_t1_50 <- sapply(mu_diff_range, power_t_welch, sigma, 50, num_simulations, alpha)
#power_t1_200 <- sapply(mu_diff_range, power_wilcox, sigma, 200, num_simulations, alpha)
#power_t1_500 <- sapply(mu_diff_range, power_t_student, sigma, 500, num_simulations, alpha)
#power_t1_1000 <- sapply(mu_diff_range, power_t_student, sigma, 1000, num_simulations, alpha)

#df_t1_n <- data.frame(mu_diff = mu_diff_range, power_t_student_10 = power_t1_10, power_t_student_50 = power_t1_50, power_t_student_200 = power_t1_200, power_t_student_500 = power_t1_500, power_t_student_1000 = power_t1_1000)

#write.csv(df_t1_n, file = "zad1_t_student_n.csv")

#power_welch_1_10 <- sapply(mu_diff_range, power_t_welch, sigma, 10, num_simulations, alpha)
#power_welch_1_50 <- sapply(mu_diff_range, power_t_welch, sigma, 50, num_simulations, alpha)
#power_welch_1_200 <- sapply(mu_diff_range, power_t_welch, sigma, 200, num_simulations, alpha)
#power_welch_1_500 <- sapply(mu_diff_range, power_t_welch, sigma, 500, num_simulations, alpha)
#power_welch_1_1000 <- sapply(mu_diff_range, power_t_welch, sigma, 1000, num_simulations, alpha)

#df_welch1_n <- data.frame(mu_diff = mu_diff_range, power_t_welch_10 = power_welch_1_10, power_t_welch_50 = power_welch_1_50, power_t_welch_200 = power_welch_1_200, power_t_welch_500 = power_welch_1_500, power_t_welch_1000 = power_welch_1_1000)

#write.csv(df_welch1_n, file = "zad1_welch_n.csv")

#power_wilcox_1_10 <- sapply(mu_diff_range, power_wilcox, sigma, 10, num_simulations, alpha)
#power_wilcox_1_50 <- sapply(mu_diff_range, power_wilcox, sigma, 50, num_simulations, alpha)
#power_wilcox_1_200 <- sapply(mu_diff_range, power_wilcox, sigma, 200, num_simulations, alpha)
#power_wilcox_1_500 <- sapply(mu_diff_range, power_wilcox, sigma, 500, num_simulations, alpha)
#power_wilcox_1_1000 <- sapply(mu_diff_range, power_wilcox, sigma, 1000, num_simulations, alpha)

#df_wilcox1_n <- data.frame(mu_diff = mu_diff_range, power_wilcox_10 = power_wilcox_1_10, power_wilcox_50 = power_wilcox_1_50, power_wilcox_200 = power_wilcox_1_200, power_wilcox_500 = power_wilcox_1_500, power_wilcox_1000 = power_wilcox_1_1000)

#write.csv(df_wilcox1_n, file = "zad1_wilcox_n.csv")
@

<<wykres rozne n, include=FALSE>>=
df_t1_n <- read.csv("zad1_t_student_n.csv")
df_welch1_n <- read.csv("zad1_welch_n.csv")
df_wilcox1_n <- read.csv("zad1_wilcox_n.csv")

#dla t1
fig1_n <- ggplot(df_t1_n, aes(x = mu_diff)) +
  geom_line(aes(y = power_t_student_10, color = "n = 10"), size = 1.5) +
  geom_line(aes(y = power_t_student_50, color = "n = 50"), size = 1.5) +
  geom_line(aes(y = power_t_student_200, color = "n = 200"), size = 1.5) +
  geom_line(aes(y = power_t_student_500, color = "n = 500"), size = 1.5) +
  geom_line(aes(y = power_t_student_1000, color = "n = 1000"), size = 1.5) +
  labs(x = expression(mu[2] - mu[1]), y = "Moc testu", colour = "n") +
  scale_colour_manual(name = "n", values = c(color1, color2, color3, color4, color5)) +
  theme_bw() +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "black")

#dla welch1_n
fig2_n <- ggplot(df_welch1_n, aes(x = mu_diff)) +
  geom_line(aes(y = power_t_welch_10, color = "n = 10"), size = 1.5) +
  geom_line(aes(y = power_t_welch_50, color = "n = 50"), size = 1.5) +
  geom_line(aes(y = power_t_welch_200, color = "n = 200"), size = 1.5) +
  geom_line(aes(y = power_t_welch_500, color = "n = 500"), size = 1.5) +
  geom_line(aes(y = power_t_welch_1000, color = "n = 1000"), size = 1.5) +
  labs(x = expression(mu[2] - mu[1]), y = "Moc testu", colour = "n") +
  scale_colour_manual(name = "n", values = c(color1, color2, color3, color4, color5)) +
  theme_bw() +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "black")

#dla wilcox1_n
fig3_n <- ggplot(df_wilcox1_n, aes(x = mu_diff)) +
  geom_line(aes(y = power_wilcox_10, color = "n = 10"), size = 1.5) +
  geom_line(aes(y = power_wilcox_50, color = "n = 50"), size = 1.5) +
  geom_line(aes(y = power_wilcox_200, color = "n = 200"), size = 1.5) +
  geom_line(aes(y = power_wilcox_500, color = "n = 500"), size = 1.5) +
  geom_line(aes(y = power_wilcox_1000, color = "n = 1000"), size = 1.5) +
  labs(x = expression(mu[2] - mu[1]), y = "Moc testu", colour = "n") +
  scale_colour_manual(name = "n", values = c(color1, color2, color3, color4, color5)) +
  theme_bw() +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "black")

print(fig1_n)
print(fig2_n)
print(fig3_n)
@


<<f1, include=FALSE>>=
df1 <- read.csv("zad1.csv")
fig1 <- ggplot(df1, aes(x = mu_diff)) +
  geom_line(aes(y = power_t_student, color = "t-Studenta"), size = 1.5) +
  geom_line(aes(y = power_t_welch, color = "t-Welcha"), size = 1.5) +
  geom_line(aes(y = power_wilcox, color= "Wilcoxona"), size =1.5) +
  labs(x = expression(mu[2] - mu[1]), y = "Moc testu", colour = "Test") +
  scale_colour_manual(name = "Test", values = c(color1, color2, color3)) +
  theme_bw() +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "black") +
  ggtitle("Wykres mocy testów")
#dodaj tytuł
print(fig1)
@

\begin{figure}[H]
\minipage{0.32\textwidth}
<<include=TRUE, echo=FALSE>>=
print(fig1_n)
@
\caption{Funkcja mocy dla testu t-Studenta w zależności od n}\label{fig:fig1_n}
\endminipage\hfill
\minipage{0.32\textwidth}
<<include=TRUE, echo=FALSE>>=
print(fig2_n)
@
\caption{Funkcja mocy dla testu t-Welcha w zależności od n}\label{fig:fig2_n}
\endminipage\hfill
\minipage{0.32\textwidth}
<<include=TRUE, echo=FALSE>>=
print(fig3_n)
@
\caption{Funkcja mocy dla testu Wilcoxona w zależności od n}\label{fig:fig3_n}
\endminipage
\end{figure}

W miejscu, gdzie różnica między średnimi $\mu_2 - \mu_1$ wynosi zero, hipoteza zerowa jest prawdziwa, co oznacza brak rzeczywistej różnicy do wykrycia przez test. Zgodnie z definicją, moc testu powinna być niska w przypadku prawdziwej hipotezy zerowej. Wiemy, że celem testu jest minimalizacja prawdopodobieństwa błędu pierwszego rodzaju, czyli odrzucenia hipotezy zerowej pomimo jej prawdziwości. Funkcja mocy osiąga minimum w punkcie, gdzie $\mu_2 - \mu_1 = 0$, dal wszystkich 3 wykresów, ponieważ testy te wykrywają różnice między próbkami, a w punkcie zerowym takiej różnicy nie ma.

\begin{figure}[H]
\centering
<<fig1, echo=FALSE, include=TRUE, fig.width=6, fig.height=4>>=
print(fig1)
@
\caption{Funkcja mocy dla testów t-Studenta, Wilcoxona i t-Welcha}
\end{figure}

Na podstawie wykresu, można zauważyć, że test t-Studenta oraz test t-Welcha  mają bardzo podobne krzywe mocy, które są najwyższe w większości zakresu wartości dla 
$\mu_2 - \mu_1$ na przedziale $(-2, 2)$. Oba te testy mają moc bliską 1 (co jest maksymalną wartością mocy testu) dla większych różnic między średnimi, co wskazuje na to, że mają one wysoką zdolność do wykrywania różnic, kiedy takowe istnieją.

Test Wilcoxona wykazuje niższą moc w porównaniu do pozostałych dwóch testów, szczególnie w obszarze wokół punktu, gdzie nie ma różnicy między średnimi $\mu_2 - \mu_1$.

Na podstawie tego wykresu można wnioskować, że testy t-Studenta i t-Welcha są jednostajnie najmocniejsze w całym zakresie wartości różnicy średnich, które są przedstawione na wykresie. Nie można jednoznacznie stwierdzić, który z nich jest mocniejszy, ponieważ ich krzywe mocy na wykresie niemal się pokrywają.


\subsection{Zadanie 2}
W tym zadaniu rozważymy próbę $(X_1, \ldots, X_{200})$ z rozkładu normalnego $N(\mu_1, 2^2)$ oraz drugą próbę $(Y_1, \ldots, Y_{200})$ z rozkładu normalnego $N(\mu_2, 4^2)$. Wykonamy wykres funkcji mocy na 
przedziale $(-2, 2)$ zawierającym przynajmniej po jednym punkcie z hipotezy zerowej i alternatywnej. Ocenimy, czy w tym przypadku istnieje test jednostajnie najmocniejszy spośród trzech rozważanych testów.

<<zad2, include=FALSE>>=
mu_diff_range <- seq(-2, 2, by = 0.05)
n <- 200
sigma1 <- 2
sigma2 <- 4
alpha <- 0.05
num_simulations <- 100

# Funkcja obliczająca moc dla testu t-Studenta
power_t_student2 <- function(mu_diff, sigma1, sigma2, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma1)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma2)
    
    test_result <- t.test(group1, group2, var.equal = TRUE)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

# Funkcja obliczająca moc dla testu t-Welcha
power_t_welch2 <- function(mu_diff, sigma1,sigma2, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma1)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma2)
    
    test_result <- t.test(group1, group2)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

# Funkcja obliczająca moc dla testu Wilcoxona
power_wilcox2 <- function(mu_diff, sigma1,sigma2, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma1)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma2)
    
    test_result <- wilcox.test(group1, group2, alternative = "greater")
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

# Obliczenia funkcji mocy dla każdego testu
#power_t2 <- sapply(mu_diff_range, power_t_student2, sigma1, sigma2, n, num_simulations, alpha)
#power_welch2 <- sapply(mu_diff_range, power_t_welch2, sigma1,sigma2, n, num_simulations, alpha)
#power_wilcox2 <- sapply(mu_diff_range, power_wilcox2, sigma1,sigma2, n, num_simulations, alpha)

# Tworzenie ramki danych
#df2 <- data.frame(mu_diff = mu_diff_range, power_t_student = power_t2, power_t_welch = power_welch2, power_wilcox = power_wilcox2)
#write.csv(df2, file = "zad2.csv")

# Wyświetlenie danych
#print(df2)
@

<<fig2, include=FALSE>>=
df2 <- read.csv("zad2.csv")
fig2 <- ggplot(df2, aes(x = mu_diff)) +
  geom_line(aes(y = power_t_student, color = "t-Studenta"), size = 1.5) +
  geom_line(aes(y = power_t_welch, color = "t-Welcha"), size = 1.5) +
  geom_line(aes(y = power_wilcox, color= "Wilcoxona"), size =1.5) +
  labs(x = expression(mu[2] - mu[1]), y = "Moc testu", colour = "Test") +
  scale_colour_manual(name = "Test", values = c(color1, color2, color3)) +
  theme_bw()+
  ggtitle("Wykres  mocy testów") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "black")

print(fig2)
@

<<zad2 dla roznych n, include=FALSE>>=
mu_diff_range <- seq(-2, 2, by = 0.05)
sigma1 <- 2
sigma2 <- 4
alpha <- 0.05
num_simulations <- 10000

power_t_student2 <- function(mu_diff, sigma1, sigma2, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma1)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma2)
    
    test_result <- t.test(group1, group2, var.equal = TRUE)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

# Funkcja obliczająca moc dla testu t-Welcha
power_t_welch2 <- function(mu_diff, sigma1,sigma2, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma1)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma2)
    
    test_result <- t.test(group1, group2)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

# Funkcja obliczająca moc dla testu Wilcoxona
power_wilcox2 <- function(mu_diff, sigma1,sigma2, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rnorm(n, mean = 0, sd = sigma1)
    group2 <- rnorm(n, mean = mu_diff, sd = sigma2)
    
    test_result <- wilcox.test(group1, group2, alternative = "greater")
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

#power_t2_10 <- sapply(mu_diff_range, power_t_student2, sigma1, sigma2, 10, num_simulations, alpha)
#power_t2_50 <- sapply(mu_diff_range, power_t_student2, sigma1, sigma2, 50, num_simulations, alpha)
#power_t2_200 <- sapply(mu_diff_range, power_t_student2, sigma1, sigma2, 200, num_simulations, alpha)
#power_t2_500 <- sapply(mu_diff_range, power_t_student2, sigma1, sigma2, 500, num_simulations, alpha)
#power_t2_1000 <- sapply(mu_diff_range, power_t_student2, sigma1, sigma2, 100, num_simulations, alpha)

#df_t2_n <- data.frame(mu_diff = mu_diff_range, power_t2_10 = power_t2_10, power_t2_50 = power_t2_50, power_t2_200 = power_t2_200, power_t2_500 = power_t2_500, power_t2_1000 = power_t2_1000)

#write.csv(df_t2_n, file = "zad2_t_student_n.csv")

#power_welch2_10 <- sapply(mu_diff_range, power_t_welch2, sigma1, sigma2, 10, num_simulations, alpha)
#power_welch2_50 <- sapply(mu_diff_range, power_t_welch2, sigma1, sigma2, 50, num_simulations, alpha)
#power_welch2_200 <- sapply(mu_diff_range, power_t_welch2, sigma1, sigma2, 200, num_simulations, alpha)
#power_welch2_500 <- sapply(mu_diff_range, power_t_welch2, sigma1, sigma2, 500, num_simulations, alpha)
#power_welch2_1000 <- sapply(mu_diff_range, power_t_welch2, sigma1, sigma2, 100, num_simulations, alpha)

#df_welch2_n <- data.frame(mu_diff = mu_diff_range, power_welch2_10 = power_welch2_10, power_welch2_50 = power_welch2_50, power_welch2_200 = power_welch2_200, power_welch2_500 = power_welch2_500, power_welch2_1000 = power_welch2_1000)

#write.csv(df_welch2_n, file = "zad2_t_welch_n.csv")

#power_wilcox2_10 <- sapply(mu_diff_range, power_wilcox2, sigma1, sigma2, 10, num_simulations, alpha)
#power_wilcox2_50 <- sapply(mu_diff_range, power_wilcox2, sigma1, sigma2, 50, num_simulations, alpha)
#power_wilcox2_200 <- sapply(mu_diff_range, power_wilcox2, sigma1, sigma2, 200, num_simulations, alpha)
#power_wilcox2_500 <- sapply(mu_diff_range, power_wilcox2, sigma1, sigma2, 500, num_simulations, alpha)
#power_wilcox2_1000 <- sapply(mu_diff_range, power_wilcox2, sigma1, sigma2, 100, num_simulations, alpha)

#df_wilcox2_n <- data.frame(mu_diff = mu_diff_range, power_wilcox2_10 = power_wilcox2_10, power_wilcox2_50 = power_wilcox2_50, power_wilcox2_200 = power_wilcox2_200, power_wilcox2_500 = power_wilcox2_500, power_wilcox2_1000 = power_wilcox2_1000)

#write.csv(df_wilcox2_n, file = "zad2_wilcox_n.csv")
@

<<figs dla roznych n zadanie2, include=FALSE>>=
df_t2_n <- read.csv("zad2_t_student_n.csv")
df_welch2_n <- read.csv("zad2_t_welch_n.csv")
df_wilcox2_n <- read.csv("zad2_wilcox_n.csv")

fig2_t_student_n <- ggplot(df_t2_n, aes(x = mu_diff)) +
  geom_line(aes(y = power_t2_10, color = "n = 10"), size = 1.5) +
  geom_line(aes(y = power_t2_50, color = "n = 50"), size = 1.5) +
  geom_line(aes(y = power_t2_200, color = "n = 200"), size = 1.5) +
  geom_line(aes(y = power_t2_500, color = "n = 500"), size = 1.5) +
  geom_line(aes(y = power_t2_1000, color = "n = 1000"), size = 1.5) +
  labs(x = expression(mu[2] - mu[1]), y = "Moc testu", colour = "n") +
  scale_colour_manual(name = "n", values = c(color1, color2, color3, color4, color5)) +
  theme_bw() +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "black")

fig2_t_welch_n <- ggplot(df_welch2_n, aes(x = mu_diff)) +
  geom_line(aes(y = power_welch2_10, color = "n = 10"), size = 1.5) +
  geom_line(aes(y = power_welch2_50, color = "n = 50"), size = 1.5) +
  geom_line(aes(y = power_welch2_200, color = "n = 200"), size = 1.5) +
  geom_line(aes(y = power_welch2_500, color = "n = 500"), size = 1.5) +
  geom_line(aes(y = power_welch2_1000, color = "n = 1000"), size = 1.5) +
  labs(x = expression(mu[2] - mu[1]), y = "Moc testu", colour = "n") +
  scale_colour_manual(name = "n", values = c(color1, color2, color3, color4, color5)) +
  theme_bw() +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "black")

fig2_wilcox_n <- ggplot(df_wilcox2_n, aes(x = mu_diff)) +
  geom_line(aes(y = power_wilcox2_10, color = "n = 10"), size = 1.5) +
  geom_line(aes(y = power_wilcox2_50, color = "n = 50"), size = 1.5) +
  geom_line(aes(y = power_wilcox2_200, color = "n = 200"), size = 1.5) +
  geom_line(aes(y = power_wilcox2_500, color = "n = 500"), size = 1.5) +
  geom_line(aes(y = power_wilcox2_1000, color = "n = 1000"), size = 1.5) +
  labs(x = expression(mu[2] - mu[1]), y = "Moc testu", colour = "n") +
  scale_colour_manual(name = "n", values = c(color1, color2, color3, color4, color5)) +
  theme_bw() +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "black")
@

\begin{figure}[H]
\minipage{0.32\textwidth}
<<include=TRUE, echo=FALSE>>=
print(fig2_t_student_n)
@
\caption{Funkcja mocy dla testu t-Studenta w zależności od n}\label{fig:fig1_n}
\endminipage\hfill
\minipage{0.32\textwidth}
<<include=TRUE, echo=FALSE>>=
print(fig2_t_welch_n)
@
\caption{Funkcja mocy dla testu t-Welcha w zależności od n}\label{fig:fig2_n}
\endminipage\hfill
\minipage{0.32\textwidth}
<<include=TRUE, echo=FALSE>>=
print(fig2_wilcox_n)
@
\caption{Funkcja mocy dla testu Wilcoxona w zależności od n}\label{fig:fig3_n}
\endminipage
\end{figure}

Analogicznie do zadania 1, w miejscu gdzie różnica między średnimi $\mu_2 - \mu_1$ wynosi zero, hipoteza zerowa jest prawdziwa, co oznacza brak rzeczywistej różnicy do wykrycia przez test.  Funkcja mocy osiąga minimum w punkcie, gdzie $\mu_2 - \mu_1 = 0$, dla wszystkich trzech wykresów, ponieważ testy te wykrywają różnice między próbkami, a w punkcie zerowym takiej różnicy nie ma.

\begin{figure}[H]
\centering
<<include=TRUE, echo=FALSE, fig.width=6, fig.height=4>>=
print(fig2)
@
\caption{Wykres funkcji mocy testów w zależności od $\mu_{2} - \mu_{1}$ dla prób z rozkładu $\mathcal{N} \sim \left(\mu, 2^2\right)$ i $\mathcal{N} \sim \left(\mu, 4^2\right)$ o długości $n=200$ przy $10^4$ krokach Monte Carlo dla $H_0: \mu_{2} = \mu_{1}$ przeciwko $\mu_{1} > \mu_{2}$.}
\label{fig:fig2}
\end{figure}

Na nowym wykresie mocy testów widzimy, że krzywe mocy dla testu t-Studenta i testu t-Welcha nadal mają bardzo podobne kształty i są bliskie wartości 1, ale teraz test Wilcoxona wykazuje wyższą moc dla wartości różnicy średnich bliskich zeru. W tym obszarze, test Wilcoxona jest lepszy od pozostałych dwóch testów, co wskazuje, że ma lepszą zdolność do wykrywania różnic, kiedy średnie są bardzo podobne do siebie.

Jednakże, gdy różnica średnich zwiększa się (zarówno w kierunku dodatnim, jak i ujemnym), test Wilcoxona ma niższą moc w porównaniu do testu t-Studenta i testu t-Welcha, które to testy wykazują moc bliską 1, co oznacza bardzo wysoką zdolność do wykrywania istotnych różnic.

Na podstawie tego wykresu można stwierdzić, że nie ma testu, który byłby jednostajnie najmocniejszy na całym zakresie różnicy średnich.

\subsection{Zadanie 3}
W kolejnym zadaniu rozważymy próbę $(X_1, \ldots, X_{200})$ z rozkładu wykładniczego $E(\frac{1}{\mu_1})$ oraz drugą próbę $(Y_1, \ldots, Y_{200})$ z rozkładu wykładniczego $E(\frac{1}{\mu_2})$. Wykonamy wykres funkcji mocy na przedziale $(0, 1)$. Sprawdzimy jak zmieniła się funkcja mocy testów i czy w tym przypadku istnieje test jednostajnie najmocniejszy spośród nich.

<<zad3, include=FALSE>>=
n <- 200
mu1 <- 1  # Stała wartość dla μ1
mu_diff_range1 <- seq(0.01, 1, length.out = 100)
alpha <- 0.05
num_simulations <- 10000

power_t_student3 <- function(mu_diff, mu, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rexp(n, rate = 1 / mu1)
    group2 <- rexp(n, rate = 1 / (mu1 + mu_diff))
    
    test_result <- t.test(group1, group2, var.equal = TRUE)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

power_t_welch3 <- function(mu_diff, mu, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rexp(n, rate = 1 / mu1)
    group2 <- rexp(n, rate = 1 / (mu1 + mu_diff))
    
    test_result <- t.test(group1, group2)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

power_wilcox3 <- function(mu_diff, mu, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rexp(n, rate = 1 / mu1)
    group2 <- rexp(n, rate = 1 / (mu1 + mu_diff))
    
    test_result <- wilcox.test(group1, group2, paired = TRUE)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}

#test wilcoxona z pseudomedianą
power_wilcox_poprawion <- function(mu_diff, mu, n, num_simulations, alpha) {
  successes <- 0
  
  for (i in 1:num_simulations) {
    group1 <- rexp(n, rate = 1 / mu1)
    group2 <- rexp(n, rate = 1 / (mu1 + mu_diff))
    
    test_result <- wilcox.test(group1, group2, mu = qgamma(0.5,2,2)*mu_diff, paired = TRUE)
    
    if (test_result$p.value < alpha) {
      successes <- successes + 1
    }
  }
  return(successes / num_simulations)
}


# Obliczenia funkcji mocy dla każdego testu
#power_t3 <- sapply(mu_diff_range1, power_t_student3, mu1, n, num_simulations, alpha)
#power_welch3 <- sapply(mu_diff_range1, power_t_welch3, mu1, n, num_simulations, alpha)
#power_wilcox_3 <- sapply(mu_diff_range1, power_wilcox3, mu1, n, num_simulations, alpha)
#power_pop <- sapply(mu_diff_range1, power_wilcox_poprawion, mu1, n, num_simulations, alpha)

# Tworzenie ramki danych
#df3 <- data.frame(Mu_Diff = mu_diff_range1, Power_T_Student = power_t3, Power_Welch = power_welch3, Power_Wilcox = power_wilcox_3, Power_Wilcox_Pop = power_pop)
#write.csv(df3, file = "zad3.csv")
#print(df3)
#length(power_t3)
@


<<fig3, include=FALSE>>=
#otowrz plik "zad3.csv"
df3 <- read.csv("zad3.csv")
print(df3)
fig3 <- ggplot(df3, aes(x = Mu_Diff)) +
  geom_line(aes(y = Power_T_Student, color = "t-Studenta"), size = 1.5) +
  geom_line(aes(y = Power_Welch, color = "t-Welcha"), size = 1.5) +
  geom_line(aes(y = Power_Wilcox, color= "Wilcoxona"), size =1.5) +
  geom_line(aes(y = Power_Wilcox_Pop, color= "Wilcoxona z pseudomedianą"), size =1.5) +
  labs(x = expression(mu[2] - mu[1]), y = "Moc testu", colour = "Test") +
  scale_colour_manual(name = "Test", values = c(color1, color2, color3, color4)) +
  theme_bw() +
  ggtitle("Wykres mocy testów") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "black")+
  ggtitle("Wykres mocy testów")
  
print(fig3)
@

\begin{figure}[H]
\centering
<<echo=FALSE, include=TRUE, fig.width=6, fig.height=4>>=
print(fig3)
@
\caption{Wykres funkcji mocy testów w zależności od $\mu_{2} - \mu_{1}$ dla prób z rozkładu wykładniczego o parametrach $\mu_1$ i $\mu_2$ o długości $n=200$ przy $10^4$ krokach Monte Carlo dla $H_0: \mu_{2} = \mu_{1}$ przeciwko $\mu_{1} > \mu_{2}$.}
\label{fig:fig3}
\end{figure}

Na wykresie 9 obserwujemy wzrost mocy testu w miarę zwiększania się wartości $\mu_{2} - \mu_{1}$. Jest to zgodne z naszymi oczekiwaniami, ponieważ moc testu wzrasta, gdy wzrasta różnica między parametrami, które porównujemy. Oznacza to, że zwiększenie różnicy między średnimi dwóch próbek zwiększa zdolność testu do poprawnego odrzucenia fałszywej hipotezy zerowej.


Rozkład wykładniczy, ze względu na swoją niesymetryczność, nie pozwala na interpretację testu Wilcoxona jako testu median. Tradycyjne podejście, zakładające symetrię rozkładu, nie jest adekwatne w tym przypadku.
Test Wilcoxona może być jednak zinterpretowany jako test pseudomediany, która dla rozkładu wykładniczego jest jednoznacznie określona.
Pseudomediana dla rozkładu wykładniczego jest równa \( q_{2,2}(0,5) \cdot \mu \), gdzie \( q_{2,2}(0,5) \) to kwantyl rzędu 0,5 rozkładu Gamma \( G(2, 2) \).
  
Na wykresie \ref{fig:fig3} przedstawiono funkcje mocy testów w zależności od różnicy parametrów dla prób z rozkładu wykładniczego o parametrach $\mu_1 = 1$ i $\mu_2 - \mu_{1}$ o długości $n=200$ przy $10^4$ krokach Monte Carlo dla $H_0: \mu_{2} = \mu_{1}$ przeciwko $\mu_{1} > \mu_{2}$. Analizując wykres mocy testów, zauważamy, że moc testów t-Studenta i t-Welcha pozostaje wysoka dla większości wartości różnicy średnich $\mu_{2} - \mu_{1}$, co sugeruje, że są one efektywne w wykrywaniu różnic między średnimi, zwłaszcza gdy różnica jest znacząca. Test Wilcoxona i test Wilcoxona z pseudomedianą wykazują niższą moc niż testy t - Welcha i t - studenta przy mniejszych różnicach średnich, ale ich moc wzrasta wraz ze wzrostem różnicy średnich. Test Wilcoxona z pseudomedianą wydaje się być lekko lepszy niż tradycyjny test Wilcoxona, co może być wynikiem lepszego dopasowania do charakterystyk danych o rozkładzie wykładniczym. Nie możemu jednak wyznaczyć jednostajnie najmocniejszego testu dla całego zakresu różnicy średnich.


\end{document}




